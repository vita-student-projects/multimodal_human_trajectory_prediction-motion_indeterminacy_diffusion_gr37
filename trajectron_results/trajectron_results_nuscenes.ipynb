{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDE Results for: int_ee\n",
      "-----------------PH: 2 -------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Unnamed: 0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unnamed: 0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27ebae79506e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mdataset_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mperf_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mperf_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"FDE Mean @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'full'].mean()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3961\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3962\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3963\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unnamed: 0'"
     ]
    }
   ],
   "source": [
    "for model in ['int_ee', 'int_ee_me', 'vel_ee', 'robot']:\n",
    "    print(f\"FDE Results for: {model}\")\n",
    "    for ph in [2, 4, 6, 8]:\n",
    "        print(f\"-----------------PH: {ph} -------------------\")\n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}_{ph}_fde_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        \n",
    "        print(f\"FDE Mean @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'full'].mean()}\")\n",
    "        del perf_df      \n",
    "        \n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}_{ph}_rv_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"RB Viols @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'full'].sum() / (len(perf_df['value'][perf_df['type'] == 'full'].index)*2000)}\")\n",
    "        del perf_df\n",
    "\n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_fde_most_likely_z.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"FDE @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'ml'].mean()}\")      \n",
    "        del perf_df\n",
    "              \n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_kde_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"KDE @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'full'].mean()}\")      \n",
    "        print(\"----------------------------------------------\")\n",
    "        del perf_df\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDE Results for: int_ee_me_no_ego\n",
      "-----------------PH: 2 -------------------\n",
      "FDE Mean @1.0s: 0.16815279412540554\n",
      "RB Viols @1.0s: 0.002895014589929844\n",
      "FDE @1.0s: 0.06937045846177256\n",
      "KDE @1.0s: -4.262019931215572\n",
      "----------------------------------------------\n",
      "-----------------PH: 4 -------------------\n",
      "FDE Mean @2.0s: 0.6655379721067188\n",
      "RB Viols @2.0s: 0.006153364996585336\n",
      "FDE @2.0s: 0.4359008486971371\n",
      "KDE @2.0s: -2.856656149202157\n",
      "----------------------------------------------\n",
      "-----------------PH: 6 -------------------\n",
      "FDE Mean @3.0s: 1.546091556287448\n",
      "RB Viols @3.0s: 0.027780530204259017\n",
      "FDE @3.0s: 1.0896218245514429\n",
      "KDE @3.0s: -1.7563896369106704\n",
      "----------------------------------------------\n",
      "-----------------PH: 8 -------------------\n",
      "FDE Mean @4.0s: 2.8358865412257397\n",
      "RB Viols @4.0s: 0.07581256596510834\n",
      "FDE @4.0s: 2.0939721352439022\n",
      "KDE @4.0s: -0.8690706892091696\n",
      "----------------------------------------------\n",
      "\n",
      "FDE Results for: robot\n",
      "-----------------PH: 2 -------------------\n",
      "FDE Mean @1.0s: 0.1295215269389519\n",
      "RB Viols @1.0s: 0.0026757717999638924\n",
      "FDE @1.0s: 0.07820393052295552\n",
      "KDE @1.0s: -3.906838146881899\n",
      "----------------------------------------------\n",
      "-----------------PH: 4 -------------------\n",
      "FDE Mean @2.0s: 0.45962341869964574\n",
      "RB Viols @2.0s: 0.0053363964614551365\n",
      "FDE @2.0s: 0.3403511030418785\n",
      "KDE @2.0s: -2.7593676749477294\n",
      "----------------------------------------------\n",
      "-----------------PH: 6 -------------------\n",
      "FDE Mean @3.0s: 1.02267032097404\n",
      "RB Viols @3.0s: 0.016484509839321176\n",
      "FDE @3.0s: 0.805915047871091\n",
      "KDE @3.0s: -1.7502450775203158\n",
      "----------------------------------------------\n",
      "-----------------PH: 8 -------------------\n",
      "FDE Mean @4.0s: 1.8380306576706953\n",
      "RB Viols @4.0s: 0.042144791478606246\n",
      "FDE @4.0s: 1.4979755853506684\n",
      "KDE @4.0s: -0.9291549495198915\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in ['int_ee_me_no_ego', 'robot']:\n",
    "    print(f\"FDE Results for: {model}\")\n",
    "    for ph in [2, 4, 6, 8]:\n",
    "        print(f\"-----------------PH: {ph} -------------------\")\n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}_{ph}_fde_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        \n",
    "        print(f\"FDE Mean @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'full'].mean()}\")\n",
    "        del perf_df      \n",
    "        \n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}_{ph}_rv_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"RB Viols @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'full'].sum() / (len(perf_df['value'][perf_df['type'] == 'full'].index)*2000)}\")\n",
    "        del perf_df\n",
    "\n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_fde_most_likely_z.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"FDE @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'ml'].mean()}\")      \n",
    "        del perf_df\n",
    "              \n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_kde_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"KDE @{ph*0.5}s: {perf_df['value'][perf_df['type'] == 'full'].mean()}\")      \n",
    "        print(\"----------------------------------------------\")\n",
    "        del perf_df\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDE Results for: vel_ee_ped\n",
      "-----------------PH: 2 -------------------\n",
      "FDE Mean @1.0s: 0.19692478207122974\n",
      "ADE Mean @1.0s: 0.14662677764789045\n",
      "KDE Mean @1.0s: -2.2747155225670865\n",
      "FDE @1.0s: 0.14044860338365958\n",
      "ADE @1.0s: 0.10269990193974571\n",
      "----------------------------------------------\n",
      "-----------------PH: 4 -------------------\n",
      "FDE Mean @2.0s: 0.4416913136048605\n",
      "ADE Mean @2.0s: 0.2619852174788723\n",
      "KDE Mean @2.0s: -1.2077850241491186\n",
      "FDE @2.0s: 0.3318094764413045\n",
      "ADE @2.0s: 0.19191957880581087\n",
      "----------------------------------------------\n",
      "-----------------PH: 6 -------------------\n",
      "FDE Mean @3.0s: 0.7274151399818707\n",
      "ADE Mean @3.0s: 0.3927783571375705\n",
      "KDE Mean @3.0s: -0.4598778937353378\n",
      "FDE @3.0s: 0.5596057458056626\n",
      "ADE @3.0s: 0.29476994666987394\n",
      "----------------------------------------------\n",
      "-----------------PH: 8 -------------------\n",
      "FDE Mean @4.0s: 1.0416545386258056\n",
      "ADE Mean @4.0s: 0.5347746967373055\n",
      "KDE Mean @4.0s: 0.13956084663150065\n",
      "FDE @4.0s: 0.8137480923873932\n",
      "ADE @4.0s: 0.4083001226167457\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in ['vel_ee_ped']:\n",
    "    print(f\"FDE Results for: {model}\")\n",
    "    for ph in [2, 4, 6, 8]:\n",
    "        print(f\"-----------------PH: {ph} -------------------\")\n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}_{ph}_fde_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"FDE Mean @{ph*0.5}s: {perf_df['value'][perf_df['metric'] == 'fde'].mean()}\")\n",
    "        del perf_df    \n",
    "              \n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_ade_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"ADE Mean @{ph*0.5}s: {perf_df['value'][perf_df['metric'] == 'ade'].mean()}\")\n",
    "        del perf_df\n",
    "              \n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_kde_full.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"KDE Mean @{ph*0.5}s: {perf_df['value'][perf_df['metric'] == 'kde'].mean()}\")\n",
    "        del perf_df  \n",
    "\n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_fde_most_likely_z.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"FDE @{ph*0.5}s: {perf_df['value'][perf_df['metric'] == 'fde'].mean()}\")      \n",
    "        del perf_df\n",
    "              \n",
    "        perf_df = pd.DataFrame()\n",
    "        for f in glob.glob(f\"results/{model}*_{ph}_ade_most_likely_z.csv\"):\n",
    "            dataset_df = pd.read_csv(f)\n",
    "            dataset_df['model'] = model\n",
    "            perf_df = perf_df.append(dataset_df, ignore_index=True)\n",
    "        del perf_df['Unnamed: 0']\n",
    "        print(f\"ADE @{ph*0.5}s: {perf_df['value'][perf_df['metric'] == 'ade'].mean()}\")      \n",
    "        del perf_df\n",
    "        print(\"----------------------------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
